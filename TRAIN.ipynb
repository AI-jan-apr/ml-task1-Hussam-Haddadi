{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25530770",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b04c3",
   "metadata": {},
   "source": [
    "- import the required machine learning libraries\n",
    "- load the Breast Cancer dataset from sklearn\n",
    "- extract features (X) and target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0651eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (569, 30)\n",
      "Shape of y: (569,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ae6d9",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f89f7",
   "metadata": {},
   "source": [
    "- split the dataset into training and testing sets\n",
    "- use 80% for training and 20% for testing\n",
    "- use stratify=y to maintain class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25efae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 455\n",
      "testing samples: 114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(\"training samples:\", X_train.shape[0])\n",
    "print(\"testing samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc092c8",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4778c",
   "metadata": {},
   "source": [
    "- Create a Logistic Regression model using default parameters.\n",
    "- train the model using training data.\n",
    "- evaluate the model using classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b94691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.9594594594594594\n",
      "Recall: 0.9861111111111112\n",
      "F1-score: 0.9726027397260274\n",
      "Confusion Matrix:\n",
      " [[39  3]\n",
      " [ 1 71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "log_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_log))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_log))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_log))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca26e7",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2005c31f",
   "metadata": {},
   "source": [
    "- create an SVM classifier with default parameters.\n",
    "- train the model on training data.\n",
    "- evaluate the model using the same metrics for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c7d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results\n",
      "Accuracy: 0.9298245614035088\n",
      "Precision: 0.9210526315789473\n",
      "Recall: 0.9722222222222222\n",
      "F1-score: 0.9459459459459459\n",
      "Confusion Matrix:\n",
      " [[36  6]\n",
      " [ 2 70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa46caf",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff627015",
   "metadata": {},
   "source": [
    "- create a KNN model using default parameters.\n",
    "- train the model using the training set.\n",
    "- evaluate its performance using the same classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa27655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results\n",
      "Accuracy: 0.9122807017543859\n",
      "Precision: 0.9428571428571428\n",
      "Recall: 0.9166666666666666\n",
      "F1-score: 0.9295774647887324\n",
      "Confusion Matrix:\n",
      " [[38  4]\n",
      " [ 6 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(\"KNN Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28c044",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c872d",
   "metadata": {},
   "source": [
    "- Summarize all evaluation metrics in one table.\n",
    "- This makes comparison between models easier.\n",
    "- Identify the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de87b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>[[39, 3], [1, 71]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>[[36, 6], [2, 70]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>[[38, 4], [6, 66]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  Logistic Regression  0.964912   0.959459  0.986111  0.972603   \n",
       "1                  SVM  0.929825   0.921053  0.972222  0.945946   \n",
       "2                  KNN  0.912281   0.942857  0.916667  0.929577   \n",
       "\n",
       "     confusion_matrix  \n",
       "0  [[39, 3], [1, 71]]  \n",
       "1  [[36, 6], [2, 70]]  \n",
       "2  [[38, 4], [6, 66]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"SVM\", \"KNN\"],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, y_pred_log),\n",
    "        accuracy_score(y_test, y_pred_svm),\n",
    "        accuracy_score(y_test, y_pred_knn)\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        precision_score(y_test, y_pred_log),\n",
    "        precision_score(y_test, y_pred_svm),\n",
    "        precision_score(y_test, y_pred_knn)\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        recall_score(y_test, y_pred_log),\n",
    "        recall_score(y_test, y_pred_svm),\n",
    "        recall_score(y_test, y_pred_knn)\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        f1_score(y_test, y_pred_log),\n",
    "        f1_score(y_test, y_pred_svm),\n",
    "        f1_score(y_test, y_pred_knn)\n",
    "    ],\n",
    "    \"confusion_matrix\":[\n",
    "        confusion_matrix(y_test, y_pred_log),\n",
    "        confusion_matrix(y_test, y_pred_svm),\n",
    "        confusion_matrix(y_test, y_pred_knn)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123978fd",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7597e",
   "metadata": {},
   "source": [
    "- The best model is the one with the highest F1-score.\n",
    "- In medical diagnosis, Recall is the most important metric.\n",
    "- Minimizing False Negatives is critical because missing a cancer case can be life-threatening."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
